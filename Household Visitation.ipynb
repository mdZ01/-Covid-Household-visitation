{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Regional Household Visitation\n",
    "\n",
    "This notebook accompanies the paper *'Household visitation during the COVID-19 pandemic' by \n",
    "Stuart Ross, George Breckenridge, Mengdie Zhuang, and Ed Manley*, published in Scientific Reports. \n",
    "\n",
    "Code segments have been extracted from the Cuebiq workbench platform, and as such some methods have been broken up and simplified to exclude database queries previously integrated within the code. \n",
    "\n",
    "The notebook contains the methods used to: \n",
    "\n",
    " 1. Estimation of visitations\n",
    " 2. Estimation of 'home and work' activity\n",
    " 3. Removing events near Greenspace and POIs, and far from residential buildings\n",
    " 5. Counting weekly active users\n",
    " 6. Household visitation rate H<sub>l,t</sub>\n",
    " 7. Estimating impact of events  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "import datetime as dt\n",
    "from linearmodels import PanelOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Constants and model parameters\n",
    "\n",
    "These current settings are in line with those described in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms_per_radian = 6371.0088\n",
    "epsilon = 0.030 / kms_per_radian\n",
    "min_samples = 3\n",
    "POI_buffer=30\n",
    "residential_buffer=50\n",
    "baseline_date=dt.date(2020,3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Estimation of visitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe trace_day contains all GPS traces captured in one day - [\"user_id\", \"lat\", \"lon\", \"event_timestamp\"]\n",
    "'''\n",
    "\n",
    "def estimate_visitations(trace_day, epsilon = epsilon, min_samples=min_samples):\n",
    "    \n",
    "    cluster_list=[]\n",
    "\n",
    "    # get visiation clusters of each user in one day using DBSCAN                  \n",
    "    for user_id, trace_id in trace_day.groupby('user_id'):\n",
    "        \n",
    "        cluster = DBSCAN(\n",
    "            eps=epsilon, \n",
    "            min_samples=min_samples, \n",
    "            algorithm='ball_tree', \n",
    "            metric='haversine'\n",
    "        ).fit(np.radians(trace_id[['lat','lon']].values))   \n",
    "        \n",
    "        if all(item == -1 for item in cluster.labels_): \n",
    "            continue\n",
    "        else:\n",
    "            # compute daily stopping threshold for each user\n",
    "            time_twostd = max(2*trace_id['event_timestamp'].diff().std(),1800)     \n",
    "            \n",
    "            trace_id['cluster_id'] = cluster.labels_\n",
    "\n",
    "            for cluster_id, cluster_group in trace_id.groupby('cluster_id'): \n",
    "                    if cluster_id == -1: \n",
    "                        continue\n",
    "\n",
    "                    # compute number of visits for each cluster                   \n",
    "                    timestamp_array=cluster_group[\"event_timestamp\"].values\n",
    "                    \n",
    "                    time_diff = np.diff(timestamp_array) \n",
    "                    \n",
    "                    index_clusterbreak=np.append(np.where(time_diff>time_twostd)[0],len(timestamp_array)-1)\n",
    "                    \n",
    "                    counter=len(index_clusterbreak)\n",
    "\n",
    "                    for index,item in enumerate(index_clusterbreak):\n",
    "                        if index == 0: \n",
    "                            diff= timestamp_array[item]-timestamp_array[0]\n",
    "                        else: \n",
    "                            diff=timestamp_array[item]-timestamp_array[index_clusterbreak[index-1]+1]\n",
    "                            \n",
    "                        if diff < 900: \n",
    "                            counter =counter - 1\n",
    "\n",
    "                    cluster_list.append([user_id, cluster_id, cluster_group['lat'].mean(),cluster_group['lon'].mean(),counter])  \n",
    "\n",
    "    return cluster_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimation of 'home and work' activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe visitation_twoweeks contains all visits identified in a two-weeks period - \n",
    "[\"user_id\",\"lat\", \"lon\", \"num_of_visits\",\"date\"]\n",
    "'''\n",
    "\n",
    "def estimate_homework(visitation_twoweeks, epsilon = epsilon, min_samples=min_samples):\n",
    "    \n",
    "    homework_list=[]\n",
    "\n",
    "    #return clusters of visitations performed by one user in two weeks using DBSCAN                  \n",
    "    for user_id, trace_id in visitation_twoweeks.groupby('user_id'):         \n",
    "        \n",
    "        cluster = DBSCAN(\n",
    "            eps=epsilon, \n",
    "            min_samples=min_samples, \n",
    "            algorithm='ball_tree', \n",
    "            metric='haversine'\n",
    "        ).fit(np.radians(trace_id[['lat','lon']].values))      \n",
    "        \n",
    "        trace_id['cluster_id'] = cluster.labels_\n",
    "\n",
    "        if all(item == -1 for item in cluster.labels_): \n",
    "            continue\n",
    "            \n",
    "        else:  \n",
    "            \n",
    "            # return two most visited locations, with the number of days visited \n",
    "            # these locations and the number of visits\n",
    "            candidate_list=[]\n",
    "            \n",
    "            for cluster_id, cluster_group in trace_id.groupby('cluster_id'):\n",
    "                \n",
    "                if cluster_id == -1: \n",
    "                    continue \n",
    "                    \n",
    "                candidate_list.append([user_id, cluster_group['lat'].mean(), cluster_group['lon'].mean(),\n",
    "                                       len(cluster_group.date.unique()),sum(cluster_group.num_of_visits)]) \n",
    "\n",
    "            homework_list.extend([candidate_list[i] for i in np.array(candidate_list)[:,-1].argsort()[-2:]])\n",
    "            \n",
    "    return homework_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Removing events near Greenspace and POIs, and far from residential buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe POI is extracted from the Ordnance Survey POI layer -  [\"id\",\"lat\", \"lon\",\"cat_num\"]\n",
    "Dataframe visit contains [\"user_id\",\"lat\", \"lon\", \"num_of_visits\",\"date\"]\n",
    "GeoDataframe greenspaces is extracted from the Ordnance Survey -  [\"id\",\"lat\", \"lon\",\"geometry\"]\n",
    "Dataframe residential is extracted from the Ordnance Survey AddressBase dataset -  [\"id\",\"lat\", \"lon\"]\n",
    "All gemetory are projected using epsg:27700\n",
    "'''\n",
    "\n",
    "visit_gpd = gpd.GeoDataFrame(visit, geometry=gpd.points_from_xy(visit.lon, visit.lat))\n",
    "\n",
    "# remove points in green space\n",
    "visit_gpd = gpd.sjoin(visit_gpd, greenspaces, how='left', op='within')\n",
    "visit_gpd = visit_gpd[visit_gpd['id'].isnull()]\n",
    "\n",
    "# remove points closer to POIs\n",
    "POI = gpd.GeoDataFrame(POI, geometry=gpd.points_from_xy(POI.lon, POI.lat))\n",
    "POI['geometry'] = POI.geometry.buffer(POI_buffer)\n",
    "temp_within = gpd.sjoin(visit_gpd, POI, op='within')\n",
    "visit_gpd = visit_gpd[~visit_gpd.index.isin(temp_within.index)]\n",
    "\n",
    "# remove if too far from residential buildings\n",
    "residential = gpd.GeoDataFrame(residential, geometry=gpd.points_from_xy(residential.lon, residential.lat))\n",
    "residential['geometry'] = residential.geometry.buffer(residential_buffer)\n",
    "visit_gpd = gpd.sjoin(visit_gpd, residential, op='within')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting weekly active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe homework contains all home and work locations identified using two weeks raw data - [\"user_id\",\"lat\", \"lon\", \"num_of_days\",\"num_of_visits\"]\n",
    "This homework datafame is updated every month\n",
    "Dataframe active_users contains all users appeared in a given day for the current month- [\"user_id\",\"date\"]\n",
    "'''\n",
    "\n",
    "def filter_active_users(active_users,homework):\n",
    "    \n",
    "    user_list = list(homework['user_id'].unique())\n",
    "    \n",
    "    active_users = active_users[active_users['cuebiq_id'].isin(user_list)]\n",
    "    \n",
    "    return active_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Household Visitation Rate H<sub>l,t</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataframe house_visit contains - [\"date\",\"LAD20NM\", \"total_users\", \"made_visit\",\"percent\"]\n",
    "'''\n",
    "\n",
    "baseline=house_visit[house_visit.date < pd.to_datetime(baseline_date)].groupby([\"LAD20NM\",\"dayofweek\"]).percent.mean().reset_index()\n",
    "\n",
    "baseline.rename(columns={\"percent\":\"baseline\"},inplace=True)\n",
    "\n",
    "house_visit=house_visit.merge(baseline, how=\"left\",on=[\"LAD20NM\",\"dayofweek\"])\n",
    "\n",
    "house_visit[\"week\"]=hv_rate.date.dt.isocalendar().week\n",
    "\n",
    "house_visit[\"h_rate\"]=(house_visit.percent-house_visit.baseline)/house_visit.baseline\n",
    "\n",
    "house_visit.sort_values(by=[\"LAD20NM\",'date'],inplace=True)\n",
    "\n",
    "house_visit.h_rate=house_visit.h_rate.fillna(0)\n",
    "\n",
    "house_visit[\"SMA_7\"]=house_visit.groupby(\"LAD20NM\").h_rate.transform(lambda x: x.rolling(7, 7,center=True).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Estimating Impact of Events  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff(date,threhold): # threshold\n",
    "    if isinstance(threhold, str): \n",
    "        temp=(date- dt.datetime.strptime(threhold,'%Y-%m-%d')).dt.days\n",
    "    else: \n",
    "        temp=(date- threhold).dt.days\n",
    "    return temp\n",
    "\n",
    "def estimate_effect(house_visit, areas, date_left,threshold,date_right):\n",
    "    '''\n",
    "    dataframe house_visit is resulted from 5 (above)\n",
    "    areas refer to a list of local authority\n",
    "    threhold, is the date when the poliy taken effect\n",
    "    date_left and data_right mark the 15 days window\n",
    "    '''\n",
    "    \n",
    "    temp=merged[(house_visit.date<date_right)&(date_left<house_visit.date)&(house_visit.LAD20NM.isin(areas))].copy()\n",
    "    \n",
    "    temp.loc[:,\"day_norm\"]=cutoff(temp['date'],threshold)\n",
    "    \n",
    "    temp = temp.assign(threshold=(temp[\"day_norm\"] >= 0).astype(int))\n",
    "    \n",
    "    temp = temp.set_index(['LAD20NM','date'])\n",
    "        \n",
    "    model = PanelOLS.from_formula(formula='h_rate ~ 1+threshold+ day_norm+threshold*day_norm + EntityEffects', data=temp)\n",
    "    \n",
    "    res = model.fit(cov_type='clustered', cluster_entity=True,cluster_time=True)\n",
    "    \n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
